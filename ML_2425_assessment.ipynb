{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1308ea1-b9a2-4f7a-b000-f41d0b38aff2",
   "metadata": {},
   "source": [
    "# Machine Learning (CMP3751M/CMP9772M) - Assessment 02\n",
    "\n",
    "Through the following notebook, you will be analysing a dataset and fitting a classification model to this dataset.\n",
    "\n",
    "The assessment is structured as follows:\n",
    "- [Dataset description](#Dataset-description)\n",
    "- [Loading the dataset](#Loading-the-dataset)\n",
    "- [Simple classification model](#Simple-classification-model)\n",
    "    - [Creating a training and testing set](#Creating-a-training-and-testing-set)\n",
    "    - [Training a classifier](#Training-a-classifier)\n",
    "- [Improved evaluation strategy](#Improved-evaluation-strategy)\n",
    "- [Different models and parameter search](#Different-models-and-parameter-search)\n",
    "- [Ensembles](#Ensembles)\n",
    "- [Final model evaluation](#Final-model-evaluation)\n",
    "- [References](#References)\n",
    "\n",
    "**Notes:**\n",
    "- Any discussion not supported by your implementation will not be awarded marks.\n",
    "- **Do not modify** any code provided as a **TESTING CELL**.\n",
    "- Make sure to **fix all the random seeds** in any parts of your solution, so it can be reproduced exactly.\n",
    "- The notebook, as provided, runs without errors (without solving the assessment). Make sure that the solution, or the partial solution, you hand in, also **runs without errors** on the data provided. If you have a partial solution causing errors which you would like to show, please include it as a comment.\n",
    "- Take care to include references to any external sources used. Check the [References](#References) section, the below cell, and the exambles through the assessment text for examples of how to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54719c9-3bc8-47c1-b620-831b73083ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to reference your sources! Check the bottom of the file, and examples used in the text of the assessment,\n",
    "# for including references to papers and software in your textual answers\n",
    "\n",
    "# Also add a reference in your solution cell before defining a class/function/method, eg.:\n",
    "\n",
    "# This code is a modified and extended version of [3]\n",
    "# OR\n",
    "# This code is a modified and extended version of https://stackoverflow.com/q/522563/884412\n",
    "##############\n",
    "## THE CODE ##\n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af12af-dd93-44ba-a161-dbab8f2017c0",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "The the assessment will be done on the dataset containing only numerical features describing the size and shape features of different varieties of dry beans [1]. (The dataset for this assessment has been adapted from the full dataset which can be found [here](https://www.muratkoklu.com/datasets/) [2]), shared in the public domain by the author).\n",
    "\n",
    "Each sample describes the measurements of a bean of a single variety, and consists of following 16 features:\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Area`       | `float` | Area of the bean in pixels. |\n",
    "| `Perimeter` | `float` | Bean circumference is defined as the length of its border. |\n",
    "| `MajorAxisLength` | `float` | The distance between the ends of the longest line that can be drawn from a bean. |\n",
    "| `MinorAxisLength` | `float` | The longest line that can be drawn from the bean while standing perpendicular to the main axis. |\n",
    "| `AspectRatio` | `float` | The ratio between the major and minor axis length. |\n",
    "| `Eccentricity` | `float` | Eccentricity of the ellipse having the same moments as the region. |\n",
    "| `ConvexArea` | `int` | Number of pixels in the smallest convex polygon that can contain the area of a bean seed. |\n",
    "| `EquivDiameter` | `float` | The diameter of a circle having the same area as a bean seed area. |\n",
    "| `Extent` | `float` | The ratio of the pixels in the bounding box to the bean area. |\n",
    "| `Solidity` | `float` | Also known as convexity. The ratio of the pixels in the convex shell to those found in beans. |\n",
    "| `Roundness`| `float` | Measures the roundness of an object. |\n",
    "| `Compactness` | `float` | An alternative measure of object roundness. |\n",
    "| `ShapeFactor1` | `float` | Shape features according to [4] |\n",
    "| `ShapeFactor2` | `float` | Shape features according to [4] |\n",
    "| `ShapeFactor3` | `float` | Shape features according to [4] |\n",
    "| `ShapeFactor4` | `float` | Shape features according to [4] |\n",
    "\n",
    "\n",
    "\n",
    "The goal for the assessment is to predict the variety of bean, listed in the last column, which provides a classification for each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Class`  | `string`: class designation | The variety of dry bean. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3ee2b-8c56-49f4-a5da-bbc7330283cb",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The dataset is given in _beans.csv_ file provided on Blackboard. **Load the dataset into two [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html)s.**: \n",
    "- The variable `X` should be a 2D [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) containing all the samples and their features from the dataset, one sample per row. \n",
    "- The variable `y` should be a 1D [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) containing the ground truth (class) as given in the `'Class'` field of the _.csv_ file.\n",
    "- _Note_: The class in the `'Class'` column is given as a string. Make sure you encode the class as an integer number in your ground truth `y`.\n",
    "- _Note_: You should make sure that your code for loading the dataset is guided by the information about the dataset, and the dataset description you provide as your answer.\n",
    "\n",
    "**Describe the dataset**. Provide a basic description of the dataset. How many samples are there in the dataset? How many distinct classes? What types of features describe the samples in the dataset? Are there any missing values in the dataset? (Make sure these are properly handled). \n",
    "- _Note_: Make sure all your answers are supported by your implementation. Answers not supported by your implementation will not score any marks.\n",
    "\n",
    "Provide your code to _load the dataset_ and the code that will allow you to _describe the dataset_ in the **SOLUTION CELL**. Provide your description of the dataset in the **ANSWER CELL**. A correct solution should result in no errors when running the **TESTING CELL** provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc2b74-5ce4-47ba-815a-138e893c599c",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae8e88a2-d3c4-4b7a-b8b9-b679fa6f6b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68035</td>\n",
       "      <td>1022.207</td>\n",
       "      <td>355.899595</td>\n",
       "      <td>244.028109</td>\n",
       "      <td>1.458437</td>\n",
       "      <td>0.727917</td>\n",
       "      <td>69243</td>\n",
       "      <td>294.321002</td>\n",
       "      <td>0.797017</td>\n",
       "      <td>0.982554</td>\n",
       "      <td>0.818210</td>\n",
       "      <td>0.826978</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.683892</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66871</td>\n",
       "      <td>990.128</td>\n",
       "      <td>372.968458</td>\n",
       "      <td>229.417890</td>\n",
       "      <td>1.625717</td>\n",
       "      <td>0.788439</td>\n",
       "      <td>67765</td>\n",
       "      <td>291.792395</td>\n",
       "      <td>0.801868</td>\n",
       "      <td>0.986807</td>\n",
       "      <td>0.857166</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.612074</td>\n",
       "      <td>0.995058</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89235</td>\n",
       "      <td>1197.862</td>\n",
       "      <td>395.687961</td>\n",
       "      <td>288.807741</td>\n",
       "      <td>1.370074</td>\n",
       "      <td>0.683567</td>\n",
       "      <td>90764</td>\n",
       "      <td>337.071996</td>\n",
       "      <td>0.769082</td>\n",
       "      <td>0.983154</td>\n",
       "      <td>0.781505</td>\n",
       "      <td>0.851863</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.725671</td>\n",
       "      <td>0.994223</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60408</td>\n",
       "      <td>999.737</td>\n",
       "      <td>369.487535</td>\n",
       "      <td>208.936425</td>\n",
       "      <td>1.768421</td>\n",
       "      <td>0.824765</td>\n",
       "      <td>61404</td>\n",
       "      <td>277.333472</td>\n",
       "      <td>0.742478</td>\n",
       "      <td>0.983780</td>\n",
       "      <td>0.759509</td>\n",
       "      <td>0.750590</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.563385</td>\n",
       "      <td>0.996301</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70344</td>\n",
       "      <td>1037.985</td>\n",
       "      <td>378.651095</td>\n",
       "      <td>237.909773</td>\n",
       "      <td>1.591574</td>\n",
       "      <td>0.777964</td>\n",
       "      <td>71521</td>\n",
       "      <td>299.273725</td>\n",
       "      <td>0.821354</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.820455</td>\n",
       "      <td>0.790368</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.624682</td>\n",
       "      <td>0.994227</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
       "0  68035   1022.207       355.899595       244.028109     1.458437   \n",
       "1  66871    990.128       372.968458       229.417890     1.625717   \n",
       "2  89235   1197.862       395.687961       288.807741     1.370074   \n",
       "3  60408    999.737       369.487535       208.936425     1.768421   \n",
       "4  70344   1037.985       378.651095       237.909773     1.591574   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0      0.727917       69243     294.321002  0.797017  0.982554   0.818210   \n",
       "1      0.788439       67765     291.792395  0.801868  0.986807   0.857166   \n",
       "2      0.683567       90764     337.071996  0.769082  0.983154   0.781505   \n",
       "3      0.824765       61404     277.333472  0.742478  0.983780   0.759509   \n",
       "4      0.777964       71521     299.273725  0.821354  0.983543   0.820455   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0     0.826978      0.005231      0.001509      0.683892      0.997413   \n",
       "1     0.782351      0.005577      0.001289      0.612074      0.995058   \n",
       "2     0.851863      0.004434      0.001440      0.725671      0.994223   \n",
       "3     0.750590      0.006117      0.001198      0.563385      0.996301   \n",
       "4     0.790368      0.005383      0.001296      0.624682      0.994227   \n",
       "\n",
       "      Class  \n",
       "0  BARBUNYA  \n",
       "1  BARBUNYA  \n",
       "2  BARBUNYA  \n",
       "3  BARBUNYA  \n",
       "4  BARBUNYA  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv('beans.csv')\n",
    "\n",
    "\n",
    "data = data.bfill()  # #Handling missing data https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html\n",
    "\n",
    "#Seperating features and class as required\n",
    "X = data.drop(columns = ['Class']).values #Store all features except class in x\n",
    "y = data['Class'].values #Store Class Labels\n",
    "\n",
    "#Encode class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)  #converts string to integer\n",
    "\n",
    "data.head() #Output the head to see a preview of the dataset using the .head() method. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae52cc-9f39-4009-b684-cafb1cd35361",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d3ed4f9-8d94-41f8-8f12-b18919fbe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(X.shape) == 2)\n",
    "assert(len(y.shape) == 1)\n",
    "assert(X.shape[0] == y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60db068-206c-4471-8b54-780a653cc315",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4e42d-cc07-4982-91fb-97c7b2f282a1",
   "metadata": {},
   "source": [
    "1. The dataset contains 2900 samples.\n",
    "2. The dataset contains 16 Numerical Features stored in X, these describe the geometric properties. The dataset also contains 1 Categorical feature Class stored in y.\n",
    "3. There are 7 Unique Classes in the dataset. ( BARBUNYA , BOMBAY , CALI , DERMASON , HOROZ , SEKER, SIRA )\n",
    "4. Missing Values were handled using the backward fill function ( .bfill() ) which copies the next downward target in the column to fill the missing value. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0117c-fdca-4d5a-9139-c0addbeb94a2",
   "metadata": {},
   "source": [
    "## Simple classification model\n",
    "\n",
    "To get the feel for the dataset, the first step will be to build train a simple classification model for this dataset. Do this in two steps detailed below:\n",
    "1. Set aside some data for training and for testing.\n",
    "2. Train a simple classifier on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac10b8-eac0-4b64-a82e-40781846c8d1",
   "metadata": {},
   "source": [
    "### Creating a training and testing set\n",
    "\n",
    "**Set aside 20\\% of the data for testing, and use the remaining 80\\% to train your model.** Make sure to fix any random seeds if you use any functions or methods relying on those, so your experiments are _fully repeatable_. Initialise the following variables:\n",
    "- `X_train` should contain the features corresponding to your training data.\n",
    "- `y_train` should contain the ground truth of your training data.\n",
    "- `X_test` should contain the features corresponding to your testing data.\n",
    "- `y_train` should contain the ground truth associated to your testing data.\n",
    "\n",
    "_Note:_ No additional marks will be rewarded for implementing an advanced data splitting strategy on this task. The purpose of this task is to start working with the dataset by applying a simple approach; you will have the chance to implement more complex evaluation pipelines in a later task.\n",
    "\n",
    "Provide your implementation in the **SOLUTION CELL (a)** below. A correct solution should result in no errors when running the **TESTING CELL** provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bc50e-8318-428d-b29b-220b4dadb283",
   "metadata": {},
   "source": [
    "### Training a classifier\n",
    "\n",
    "**Train a simple classifier,** (of your choosing) **with fixed parameters** on the dataset, and **calculate accuracy on the test set**.\n",
    "- Define a function `model_accuracy(y_test, y_pred)` to compare the ground truth given in `y_test` to predictions given in `y_pred` and calculate accuracy.\n",
    "- **Store the model** in the variable named `model`. For the model, you may chose any classifier with which you are familiar (e.g. K Nearest Neighbours), or implement your own classifier. Make sure you **train your model** using the _training data_ only (`X_train`, `y_train`).\n",
    "- Use the model to **predict the classes of the data** in the testing set (`X_test`), and calculate the accuracy by comparing the predictions with the ground truth for the testing set (`y_test`). **Store the predictions** in a variable called `y_pred`.\n",
    "\n",
    "_Note:_ Do not implement an advanced strategy to chose the parameters of your classifier here, as that will be a topic of a latter question.\n",
    "\n",
    "_Note:_ If you implement your own classifier, make sure you implement it as a _class_ following the _sklearn_ standard for classifiers (i.e. make sure it implements the `fit(X, y)` method to train the model, and `predict(X)` method to use the trained model to predict the classes of provided samples.\n",
    "\n",
    "\n",
    "**Discuss the advantages and shortcomings** of the evaluation strategy implemented through this task. Discuss both the data split used for evaluation and the choice of metric. Taking into account the information you know about the dataset, what kind of accuracy scores can you expect on this dataset from a good and bad performing model? Based on the information you have so far, comment on the performance of the model you have trained on the provided dataset.\n",
    "\n",
    "Provide your implementation in the **SOLUTION CELL (b)** below. The **TESTING CELL** below should run without errors and will print the prediction of your model for the first sample in the test set, and the accuracy as calculated by your `model_accuracy` function. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d0156-553b-4c89-a594-fa1c88e592b4",
   "metadata": {},
   "source": [
    "**SOLUTION CELL (a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c823edbd-0d8b-4238-9ae7-db683d651b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Split the data to 80% training data 20% testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046238d-602f-4ed1-8f41-cd71fdbb853d",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31fc35ed-610c-47bc-acce-0060f0f72034",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train.shape[0] == y_train.shape[0])\n",
    "assert(X_test.shape[0] == y_test.shape[0])\n",
    "assert(X_train.shape[1] == X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af37dd-393c-4278-9972-c10677ad6189",
   "metadata": {},
   "source": [
    "**SOLUTION CELL (b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af0e7c2a-5d95-4071-ae09-68c14e00bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def model_accuracy(y_test, y_pred):\n",
    "    #Calculates the accuracy of the model using the accuracy_score function from sklearn metrics. https://www.educative.io/answers/what-is-the-accuracyscore-function-in-sklearn\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 3) # Use 3 neighbours for the knn model\n",
    "\n",
    "model.fit(X_train, y_train) #Use the training data to train the model\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4e3e6-be93-4fd5-9611-ec06c2a4610a",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b1d52b9-7543-4d59-90d6-43ad5cf08229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0.6396551724137931\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test[0].reshape(1,-1)))\n",
    "print(model_accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae302f-0899-481e-8901-de9efe493da1",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bd068-84e1-4014-8696-02e3abfe8455",
   "metadata": {},
   "source": [
    "##### Evaluation Strategy\n",
    "- Dataset was split 80% Training and 20% Testing. THis ensures the model is evaluated on unseen data, provding a quick measure of the model's performance\n",
    "- Evaluation metric used was accuracy, thios measures proprotion of correctly classified samples / the total number of samples. Given the dataset is balanaced from the information gathered so far, this this was deemeded an appropriate metric. https://www.educative.io/answers/what-is-the-accuracyscore-function-in-sklearn\n",
    "\n",
    "##### Model Performance\n",
    "- Trained classifier predicted the first sample in the test (y_pred for X_test[0]) set as [0] which corressponds to the first encoded class. (BARBUNYA)\n",
    "- Overall accruacy was 63.97% (0.639655) indicating moderate performance of the model.\n",
    "- A good model would be expected achieve 90% + given the deatures in the dataset provide meaningful information and meta data about the classes.\n",
    "- A poor model woud achieve accuracy through random guessing which would be significantly lower than 63.97%\n",
    "- Due to this the current model's performance can be deemed as moderate and can be optimized using things such as hyperparameter tuning or feature selection.\n",
    "- (https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn)\n",
    "\n",
    "##### Shortcomings\n",
    "- With a single train-test split, the performance may depend on how the data was split, leading to unreliable results and variablity in results. https://builtin.com/data-science/train-test-split , https://towardsdatascience.com/3-tips-for-working-with-imbalanced-datasets-a765a0f3a0d0\n",
    "- While accuracy provides an over all metric on the model's performance, it does not provide any insight on how the model performed for each class. In datasets with imbalanced classes metrics such as precision recall and F1-score are important to provide these insights. https://keylabs.ai/blog/understanding-the-f1-score-and-auc-roc-curve/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa832abe-5688-43e2-8d1f-b655b7d4b142",
   "metadata": {},
   "source": [
    "## Improved evaluation strategy\n",
    "\n",
    "After discussing the shortcomings of the simple evaluation strategy used in the previous task, you now have a chance to **propose a better evaluation strategy.** Make sure your chosen strategy **uses all the samples in the dataset** to report the result.\n",
    "- **Implement a function** `evaluate_model(model, X, y)` to implement your proposed evaluation strategy. The function should evaluate the model given in `model` on the dataset given by `X` with ground truth given by `y`. Note that the function should be passed the _whole of the dataset_ (see **TESTING CELL** below) and should take care of any data splitting internally.\n",
    "- If desired, you may add additional arguments to this function, as long as they have default values and the function runs correctly when called using those default values.\n",
    "- The function should return no values, but instead print the results of the evaluation in a human-readable format.\n",
    "- Include at least one summative metric (providing a single number, e.g. accuracy) and per-class metric (e.g. precision) calculated for every class. You are encouraged to select more than one metric of each type.\n",
    "\n",
    "This function will be used to provide a better evaluation of the simple model with fixed parameters used in the previous task.\n",
    "\n",
    "**Discuss your chosen evaluation strategy**, including both the data split and the evaluation metrics. Which data splitting strategy did you chose and why? Which metrics did you chose, and why? Briefly explain the chosen data splitting strategy. What additional information can your additional metrics provide beyond accuracy?\n",
    "\n",
    "Provide your implementation of this function in the **SOLUTION CELL**. You may also include any additional evaluation calls you want to include in this code cell. The **TESTING CELL** will perform a basic evaluation of your `model` using the `evaluate_model` function implemented for this task. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e4c6a-7818-4b68-a7db-14e73dae16b8",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd9c1591-9cfa-4831-9f56-d42557f31897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, X, y): #n_folds defines the number of folds used for cross-validation\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle= True, random_state=42)\n",
    "    fold = 1\n",
    "    accuracies = [] #Empty array to hold accuracy to calculate the Mean Accuracy and Standard Diviation of Accuracy\n",
    "    print('Cross Validation Results:')\n",
    "    print('=' * 50) # Creates after the title for a cleaner output layout and more interperetable\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        #Split data for current fold index for iteration purposes\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #Train Model using current fold split\n",
    "        model.fit(X_train, y_train)\n",
    "        #Make Prediction\n",
    "        y_pred = model.predict(X_test)\n",
    "        #Calculate Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy) #Append the current fold's accuracy to the accuracies array\n",
    "\n",
    "        #Printing out the acccuracy and metrics per class\n",
    "        print(f'Fold {fold} Accuracy: {accuracy:.4f}') #Outputs the fold number and accuracy of that fold\n",
    "        print(f'Metric Per Class:')\n",
    "        #Output the classification report for current fold, showing the precision / recall / f1-score / support for each class label\n",
    "        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_)) #https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html\n",
    "        print('-' * 50) #Creates a line at the bottom of the current classifcation report to seperate it from the next fold\n",
    "        fold += 1 #Iterate thropugh the folds in the for loop to move to the next train and test index\n",
    "\n",
    "     # Summarize results across folds\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"Standard Deviation: {np.std(accuracies):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6d8f2-fae8-4f49-839c-3c145b4573c3",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73a5b7ca-e08d-4bf0-8b0b-2aeb4ee4982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Results:\n",
      "==================================================\n",
      "Fold 1 Accuracy: 0.6914\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.43      0.46      0.44        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.59      0.57      0.58        60\n",
      "    DERMASON       0.79      0.92      0.85       200\n",
      "       HOROZ       0.69      0.62      0.65        60\n",
      "       SEKER       0.62      0.36      0.46        80\n",
      "        SIRA       0.64      0.67      0.66       110\n",
      "\n",
      "    accuracy                           0.69       580\n",
      "   macro avg       0.68      0.66      0.66       580\n",
      "weighted avg       0.68      0.69      0.68       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 2 Accuracy: 0.6638\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.46      0.46      0.46        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.65      0.62      0.63        60\n",
      "    DERMASON       0.76      0.86      0.81       200\n",
      "       HOROZ       0.57      0.45      0.50        60\n",
      "       SEKER       0.68      0.34      0.45        80\n",
      "        SIRA       0.56      0.71      0.63       110\n",
      "\n",
      "    accuracy                           0.66       580\n",
      "   macro avg       0.67      0.63      0.64       580\n",
      "weighted avg       0.66      0.66      0.65       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 3 Accuracy: 0.6828\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.36      0.36      0.36        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.61      0.58      0.60        60\n",
      "    DERMASON       0.79      0.90      0.84       200\n",
      "       HOROZ       0.51      0.60      0.55        60\n",
      "       SEKER       0.73      0.38      0.50        80\n",
      "        SIRA       0.68      0.70      0.69       110\n",
      "\n",
      "    accuracy                           0.68       580\n",
      "   macro avg       0.67      0.65      0.65       580\n",
      "weighted avg       0.68      0.68      0.67       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 4 Accuracy: 0.6655\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.43      0.60      0.50        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.68      0.53      0.60        60\n",
      "    DERMASON       0.79      0.89      0.84       200\n",
      "       HOROZ       0.52      0.50      0.51        60\n",
      "       SEKER       0.55      0.38      0.44        80\n",
      "        SIRA       0.62      0.60      0.61       110\n",
      "\n",
      "    accuracy                           0.67       580\n",
      "   macro avg       0.66      0.64      0.64       580\n",
      "weighted avg       0.66      0.67      0.66       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 5 Accuracy: 0.6724\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.43      0.50      0.46        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.60      0.55      0.57        60\n",
      "    DERMASON       0.80      0.90      0.85       200\n",
      "       HOROZ       0.58      0.48      0.53        60\n",
      "       SEKER       0.60      0.47      0.53        80\n",
      "        SIRA       0.59      0.59      0.59       110\n",
      "\n",
      "    accuracy                           0.67       580\n",
      "   macro avg       0.66      0.64      0.65       580\n",
      "weighted avg       0.67      0.67      0.67       580\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Mean Accuracy: 0.6752\n",
      "Standard Deviation: 0.0105\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46babc-b9bb-4825-9a24-2f4ef812d493",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6281e9-3b43-41fd-9c67-fd2caf83a071",
   "metadata": {},
   "source": [
    "##### Chosen Evaluation Strategy\n",
    "- Stratified K-Fold Cross Validation was used as it ensures all samples are used for training and testing. Cross Validation also maintains class proportions in each fold which is important for datasets with imbalanced classes. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "- Using multiple splits, in this case 5 splits reduces the variance in evaluation and helps us obtain reliable estimates on the model's generalization performance in comparison to using a single train test split. https://towardsdatascience.com/3-tips-for-working-with-imbalanced-datasets-a765a0f3a0d0\n",
    "##### Chosen Metrics\n",
    "- Accuracy measures the overall correctness or accuracy of the predictions made by the model. This is a standard metric when evaluating a model's performance.\n",
    "- Precision Recall and F1 - Score were chosen as they give more in depth insight on how the model handles each indivual class.\n",
    "    - Precision provides an insight on the relevance of the predictions made.\n",
    "    - Recall measures the ability to retrieve all relevant instances in the class.\n",
    "    - F1-Score is used to balance precision and recall offering a balanced measure of a classifier's performance. It is very useful for imbalanced datasets where FP and FN play a significant role. https://keylabs.ai/blog/understanding-the-f1-score-and-auc-roc-curve/\n",
    "\n",
    "##### Advantages of New Evaluation Strategy\n",
    "- Cross Validation ensures a robust evaluation as it uses all data for training and testing, reducing the biases due to the 5 splits it creates.\n",
    "- The per class metrics provided by my new evaluation strategy provide a deeper insight on how the model performs for each class. This can help identify classes that are poorly handled by the model. After reviewing the evaluation it is evident that our model's performance is poor when it comes to the classes BARBUNYA and SEKER as the f1 scores for these are the lowest across all 5 folds.\n",
    "- The mean and standard diviation of the acurracy across all folds of the evaluation model provides an estimate of the model's stability and consistency as well as over all performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce4cf3-0f68-4884-bf55-e76eed093144",
   "metadata": {},
   "source": [
    "## Different models and parameter search\n",
    "\n",
    "Now that you have a [better evaluation strategy](#Improved-evaluation-strategy) implemented, it is time to try out different models, and try out different parameter combinations for these models.\n",
    "\n",
    "**Fit at least three different (types of) machine learning models** to the provided dataset. (_Note:_ Make sure at least 2 out of your 3 chosen types have different model parameters which can be adjusted). **Try different parameters for all of your models** (which have parameters). Use a single summative metric of your choice to choose between the different types of models, and the models with different parameters. Finally, **choose thee different models, one of each type** and assign them to variables `model_1`, `model_2` and `model_3`.\n",
    "\n",
    "**Discuss your choice of models, and your procedure to adjust the model parameters**. Discuss how you reached the decision about the best model amongst the models of the same type (which metric was selected, and why). Also discuss any shortcomings of your approach and how (and if) you could improve on this. After evaluating these models on the dataset, **discuss and compare their performance on the provided data.**\n",
    "\n",
    "Implement your solution in the **SOLUTION CELL**. The **TESTING CELL** will evaluate the three best models selected by you, using your evaluation strategy. Discuss your choices in the **ANSWER CELL**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353db6d-39a5-4022-bee1-4b55d5bb4d09",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adfbbe1a-4a42-4681-859b-bc4bf348d5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression: {'C': 10}\n",
      "Best accuracy for LogisticRegression: 0.8652\n",
      "--------------------------------------------------\n",
      "Best parameters for SVC: {'C': 0.1, 'kernel': 'linear'}\n",
      "Best accuracy for SVC: 0.9138\n",
      "--------------------------------------------------\n",
      "Best parameters for DecisionTreeClassifier: {'criterion': 'gini', 'max_depth': 10}\n",
      "Best accuracy for DecisionTreeClassifier: 0.8972\n",
      "--------------------------------------------------\n",
      "Best LogisticRegression Model: LogisticRegression(C=10, max_iter=1000, solver='liblinear')\n",
      "Best SVM Model: SVC(C=0.1, kernel='linear')\n",
      "Best DecisionTree Model: DecisionTreeClassifier(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Define Model 1 and the paramters to be tested\n",
    "log_reg = LogisticRegression (max_iter = 1000, solver= 'liblinear') #https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "log_params = {'C': [0.1, 1, 10]} #https://drbeane.github.io/python_dsci/pages/grid_search.html\n",
    "#Define Model 2 and the parameters to be tested\n",
    "svm = SVC() #https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\n",
    "svm_params = {'C' : [0.1, 1, 10], 'kernel':['linear', 'rbf']}\n",
    "#Define Model 3 and the parameters to be tested\n",
    "dec_tree = DecisionTreeClassifier() #https://scikit-learn.org/1.5/modules/tree.html\n",
    "dec_tree_params = {'max_depth': [None, 10, 20],'criterion':['gini', 'entropy']}\n",
    "\n",
    "def find_best_params(model, params, X, y): #Find best parameters using grid search and param list for each model https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/\n",
    "    grid_search = GridSearchCV(model, params, cv = StratifiedKFold(n_splits= 5, shuffle=True, random_state=42), scoring = 'accuracy')\n",
    "    grid_search.fit(X,y)\n",
    "    best_params_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\") #Prints out the best parameters for model\n",
    "    print(f\"Best accuracy for {model.__class__.__name__}: {grid_search.best_score_:.4f}\")#Prints out the accuracy of model with these parameters\n",
    "    print('-' * 50)\n",
    "    return best_params_model\n",
    "\n",
    "\n",
    "#Find the best parameters model\n",
    "model_1 = find_best_params(log_reg,log_params, X, y)\n",
    "model_2 = find_best_params(svm, svm_params, X, y)\n",
    "model_3 = find_best_params(dec_tree, dec_tree_params, X, y)\n",
    "\n",
    "#Print the best models\n",
    "print(\"Best LogisticRegression Model:\", model_1)\n",
    "print(\"Best SVM Model:\", model_2)\n",
    "print(\"Best DecisionTree Model:\", model_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a52581-71a4-4c75-bc3a-861fe83e40a4",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2131851-eb53-4b64-8b12-d53af5612328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model 1, Logistic Regression Model:\n",
      "\n",
      "Cross Validation Results:\n",
      "==================================================\n",
      "Fold 1 Accuracy: 0.8569\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.85      0.88      0.86        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.97      0.58      0.73        60\n",
      "    DERMASON       0.88      0.93      0.90       200\n",
      "       HOROZ       0.89      0.92      0.90        60\n",
      "       SEKER       0.95      0.91      0.93        80\n",
      "        SIRA       0.69      0.77      0.73       110\n",
      "\n",
      "    accuracy                           0.86       580\n",
      "   macro avg       0.89      0.86      0.87       580\n",
      "weighted avg       0.87      0.86      0.86       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 2 Accuracy: 0.8552\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.91      0.82      0.86        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.89      0.57      0.69        60\n",
      "    DERMASON       0.87      0.95      0.91       200\n",
      "       HOROZ       0.93      0.93      0.93        60\n",
      "       SEKER       0.96      0.90      0.93        80\n",
      "        SIRA       0.67      0.75      0.70       110\n",
      "\n",
      "    accuracy                           0.86       580\n",
      "   macro avg       0.89      0.85      0.86       580\n",
      "weighted avg       0.86      0.86      0.85       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 3 Accuracy: 0.8690\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.86      0.91        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.95      0.63      0.76        60\n",
      "    DERMASON       0.92      0.91      0.91       200\n",
      "       HOROZ       0.93      0.93      0.93        60\n",
      "       SEKER       0.96      0.90      0.93        80\n",
      "        SIRA       0.65      0.85      0.74       110\n",
      "\n",
      "    accuracy                           0.87       580\n",
      "   macro avg       0.91      0.87      0.88       580\n",
      "weighted avg       0.89      0.87      0.87       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 4 Accuracy: 0.8655\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.88      0.84      0.86        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.91      0.68      0.78        60\n",
      "    DERMASON       0.89      0.94      0.91       200\n",
      "       HOROZ       0.95      0.92      0.93        60\n",
      "       SEKER       0.97      0.91      0.94        80\n",
      "        SIRA       0.68      0.75      0.72       110\n",
      "\n",
      "    accuracy                           0.87       580\n",
      "   macro avg       0.90      0.86      0.88       580\n",
      "weighted avg       0.87      0.87      0.87       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 5 Accuracy: 0.8793\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.93      0.82      0.87        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.93      0.67      0.78        60\n",
      "    DERMASON       0.89      0.96      0.93       200\n",
      "       HOROZ       0.92      0.95      0.93        60\n",
      "       SEKER       0.95      0.89      0.92        80\n",
      "        SIRA       0.74      0.80      0.77       110\n",
      "\n",
      "    accuracy                           0.88       580\n",
      "   macro avg       0.91      0.87      0.88       580\n",
      "weighted avg       0.88      0.88      0.88       580\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Mean Accuracy: 0.8652\n",
      "Standard Deviation: 0.0088\n",
      "//////////////////////////////////////////////////\n",
      "Evaluating Model 2, SVM Model:\n",
      "\n",
      "Cross Validation Results:\n",
      "==================================================\n",
      "Fold 1 Accuracy: 0.9293\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.88      0.92        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.89      0.97      0.93        60\n",
      "    DERMASON       0.94      0.93      0.94       200\n",
      "       HOROZ       0.97      0.95      0.96        60\n",
      "       SEKER       0.95      0.94      0.94        80\n",
      "        SIRA       0.87      0.90      0.88       110\n",
      "\n",
      "    accuracy                           0.93       580\n",
      "   macro avg       0.94      0.94      0.94       580\n",
      "weighted avg       0.93      0.93      0.93       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 2 Accuracy: 0.8845\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.93      0.78      0.85        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.95      0.93      0.94        60\n",
      "    DERMASON       0.88      0.92      0.90       200\n",
      "       HOROZ       0.93      0.92      0.92        60\n",
      "       SEKER       0.92      0.89      0.90        80\n",
      "        SIRA       0.78      0.80      0.79       110\n",
      "\n",
      "    accuracy                           0.88       580\n",
      "   macro avg       0.91      0.89      0.90       580\n",
      "weighted avg       0.89      0.88      0.88       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 3 Accuracy: 0.9103\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.98      0.88      0.93        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.92      0.95      0.93        60\n",
      "    DERMASON       0.94      0.89      0.91       200\n",
      "       HOROZ       0.92      0.97      0.94        60\n",
      "       SEKER       0.94      0.91      0.92        80\n",
      "        SIRA       0.80      0.90      0.85       110\n",
      "\n",
      "    accuracy                           0.91       580\n",
      "   macro avg       0.93      0.93      0.93       580\n",
      "weighted avg       0.91      0.91      0.91       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 4 Accuracy: 0.9276\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.89      0.94      0.91        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.93      0.95      0.94        60\n",
      "    DERMASON       0.93      0.95      0.94       200\n",
      "       HOROZ       0.95      0.90      0.92        60\n",
      "       SEKER       0.97      0.95      0.96        80\n",
      "        SIRA       0.88      0.85      0.87       110\n",
      "\n",
      "    accuracy                           0.93       580\n",
      "   macro avg       0.94      0.93      0.94       580\n",
      "weighted avg       0.93      0.93      0.93       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 5 Accuracy: 0.9172\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.80      0.87        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.88      0.98      0.93        60\n",
      "    DERMASON       0.90      0.95      0.93       200\n",
      "       HOROZ       0.98      0.98      0.98        60\n",
      "       SEKER       0.94      0.91      0.92        80\n",
      "        SIRA       0.88      0.83      0.85       110\n",
      "\n",
      "    accuracy                           0.92       580\n",
      "   macro avg       0.93      0.92      0.93       580\n",
      "weighted avg       0.92      0.92      0.92       580\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Mean Accuracy: 0.9138\n",
      "Standard Deviation: 0.0162\n",
      "//////////////////////////////////////////////////\n",
      "Evaluating Model 3, Decision Tree Model:\n",
      "\n",
      "Cross Validation Results:\n",
      "==================================================\n",
      "Fold 1 Accuracy: 0.8966\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.92      0.94        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.92      0.93      0.93        60\n",
      "    DERMASON       0.93      0.87      0.90       200\n",
      "       HOROZ       0.92      0.92      0.92        60\n",
      "       SEKER       0.92      0.90      0.91        80\n",
      "        SIRA       0.78      0.88      0.83       110\n",
      "\n",
      "    accuracy                           0.90       580\n",
      "   macro avg       0.92      0.92      0.92       580\n",
      "weighted avg       0.90      0.90      0.90       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 2 Accuracy: 0.8741\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.89      0.84      0.87        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.96      0.88      0.92        60\n",
      "    DERMASON       0.90      0.89      0.89       200\n",
      "       HOROZ       0.93      0.92      0.92        60\n",
      "       SEKER       0.83      0.90      0.86        80\n",
      "        SIRA       0.76      0.79      0.78       110\n",
      "\n",
      "    accuracy                           0.87       580\n",
      "   macro avg       0.90      0.89      0.89       580\n",
      "weighted avg       0.88      0.87      0.87       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 3 Accuracy: 0.9052\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.85      0.90      0.87        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.92      0.90      0.91        60\n",
      "    DERMASON       0.94      0.91      0.92       200\n",
      "       HOROZ       0.92      0.90      0.91        60\n",
      "       SEKER       0.89      0.93      0.91        80\n",
      "        SIRA       0.85      0.88      0.87       110\n",
      "\n",
      "    accuracy                           0.91       580\n",
      "   macro avg       0.91      0.92      0.91       580\n",
      "weighted avg       0.91      0.91      0.91       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 4 Accuracy: 0.8966\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.86      0.88      0.87        50\n",
      "      BOMBAY       0.95      1.00      0.98        20\n",
      "        CALI       0.86      0.92      0.89        60\n",
      "    DERMASON       0.90      0.92      0.91       200\n",
      "       HOROZ       0.92      0.90      0.91        60\n",
      "       SEKER       0.96      0.91      0.94        80\n",
      "        SIRA       0.86      0.83      0.84       110\n",
      "\n",
      "    accuracy                           0.90       580\n",
      "   macro avg       0.90      0.91      0.90       580\n",
      "weighted avg       0.90      0.90      0.90       580\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 5 Accuracy: 0.8966\n",
      "Metric Per Class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.86      0.88      0.87        50\n",
      "      BOMBAY       1.00      1.00      1.00        20\n",
      "        CALI       0.92      0.95      0.93        60\n",
      "    DERMASON       0.91      0.90      0.90       200\n",
      "       HOROZ       0.96      0.88      0.92        60\n",
      "       SEKER       0.92      0.91      0.92        80\n",
      "        SIRA       0.81      0.85      0.83       110\n",
      "\n",
      "    accuracy                           0.90       580\n",
      "   macro avg       0.91      0.91      0.91       580\n",
      "weighted avg       0.90      0.90      0.90       580\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Mean Accuracy: 0.8938\n",
      "Standard Deviation: 0.0104\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Model 1, Logistic Regression Model:\\n')\n",
    "evaluate_model(model_1, X, y)\n",
    "print('/'* 50)\n",
    "print('Evaluating Model 2, SVM Model:\\n')\n",
    "evaluate_model(model_2, X, y)\n",
    "print('/'* 50)\n",
    "print('Evaluating Model 3, Decision Tree Model:\\n')\n",
    "evaluate_model(model_3, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ae54c-06a2-4f7e-8fee-80ba278be269",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6439d8-ec84-42d3-8a75-dda5217e871f",
   "metadata": {},
   "source": [
    "##### Model Choice\n",
    "- **Logistic Regression**\n",
    "    - Logistic regression is an interpretable and simple model which excels in multi-class classification problems. This would provide a good baseline model to compare against other more complex models.\n",
    "    - The parameters tested for this model was the regularization strength ('C'). Initially I was going to also test different solvers but the Liblinear solver showed to be the most robust compared to the other solver i was testing 'lgbfs' as that was giving me warnings with the number of iterations.\n",
    "\n",
    "- **Support Vector Machine**\n",
    "    - SVM is a powerful and versatile model that handles linear and non-linear classification problems, It is particularily effective in handling high dimensional data, in the context of the beans dataset , there are multiple numerical features which the SVM can effectively utilize to find an optimal hyperplane that seperates the classes. https://www.ibm.com/think/topics/support-vector-machine\n",
    "    - The parameters tested for this model were the regularization strength ('C') and the kernel type(linear and rbf). The linear kernel was chosen due to its simplicity and effectiveness in producing a higher accuracy.\n",
    "\n",
    "- **Decision Tree**\n",
    "    - Decision Tree's are simple yet powerful models that can handle classification and regression tasks. They are easy to visualize making them easy to interpret and understand the decision making process. These trees can be used to determine feature importance, helping determine what the most influential features are when classifying beans.\n",
    "    - Parameters tested for this model were the maximum depth of the tree (max depth) and the criterion for splitting (gini and entropy). The gini was chosen for producing better results.\n",
    "\n",
    "##### HyperParameter Tuning\n",
    "- Accuracy was chosen as the metric used for evaluating the parameters of each model as it is easy to interpret and straightforward. \n",
    "- A function was created **find_best_params(model, params, X, y):** , This took in the model along with its parameters to be tested, a grid search was run on the models using cross validation with 5 folds using accuracy as the scoring. **grid_search.best_estimator_** was then used to assign the model that resulted in the best scoring (accuracy) to the variable **best_params_model**. \n",
    "- **{model.__class__.__name__}: {grid_search.best_params_}** was then used to output the best parameters for that model and **{model.__class__.__name__}: {grid_search.best_score_}** was used to output the accuracy these parameters achieved.\n",
    "- The function returned **best_params_model** which was the most accurate model from the parameters provided.\n",
    "- This function was then called model 1, 2 and 3 with their respective defintion and parameters.\n",
    "\n",
    "- **Best Model Paramters**\n",
    "    - **Logistic Regression:** the best parameters were **C= 10** with an accuracy of 0.8652.\n",
    "    - **SVM** the best paramters were **C = 10** and **kernel = 'linear'** with an accuracy of 0.9138.\n",
    "    - **Decision Tree** the best parameters were **cirterion = 'gini'** and **max_depth = 10** with an accuracy of 0.8972.\n",
    "\n",
    "##### Shortcomings and Improvements\n",
    "- **Logistic Regression**\n",
    "    - Logistic Regression may not capture complex relationships in the data as effectively as more complex data, it is more so used as a base line to compare to more complext models as mentioned.\n",
    "    - Using a different solver and higher number of maximum Iterations if higher computation power can be accessed could help improve convergence.\n",
    "\n",
    "- **Support Vector Machine** https://alekhyo.medium.com/computational-complexity-of-svm-4d3cacf2f952\n",
    "    - SVM is computationally expensive when it comes to large datasets and non-linear kernels. This caused the hyperparameter tuning of the SVM model to be significantly slower than the other models.\n",
    "    - Optimizing kernel paramters can improve performance and run time of computing best parameters, additionally using a scaling method or feature selection can enhance effectiveness.\n",
    "\n",
    "- **Decision Tree**\n",
    "    - With deep trees, decision trees can be prone to overfitting, capturing noise and outliers rather than the underlying pattern. The beans dataset contains 2900 samples and 16 Numerical Features, this makes the risk of overfitting prevelant and can lead to poor generalization.\n",
    "    - Pruning the decision tree can prevent it from becoming too complex and avoid overfitting the training data. Subsequently creating a more balanced and generalizable model. \n",
    "    https://medium.com/nerd-for-tech/overfitting-and-pruning-in-decision-trees-improving-models-accuracy-fdbe9ecd1160\n",
    "\n",
    "##### Performance Comparison and Evaluation\n",
    "- **Logistic Regression**\n",
    "    - Mean Accuracy: 0.8652\n",
    "    - Standard Diviation: 0.0088\n",
    "    - Logistic Regression performed reasonably well, with consistent accuracy across different folds. However, it had the lowest mean accuracy and unfortunately the lowest, lowest f1-score of 0.70 for the SIRA class in fold 2.\n",
    "\n",
    "- **Support Vector Machine**\n",
    "    - Mean Accuracy: 0.9138\n",
    "    - Standard Diviation: 0.0162\n",
    "    - SVM had the highest mean accuracy and performed consistently well across different folds. It showed a high precision, recall and F1-score for most classes showing that it handled most classes well, with a lowest f1-score of 0.79 for the SIRA class in fold 2.\n",
    "\n",
    "- **Decision Tree**\n",
    "    - Mean Accuracy: 0.8972\n",
    "    - Standard Diviation: 0.0104\n",
    "    - Decision Tree performed almost as well as the SVM, witha  meal accuracy almost as high. It also showed good handling for most classes, with a lowest f1-score of 0.78 for the SIRA class in fold 2. putting it on par with SVM.\n",
    "\n",
    "##### Conclusion\n",
    "- The SVM Model with C = 0.1 and kernel = 'linear' was the best performing model, with a mean accuracy of 0.9138. It showedstrong and consistent performance across different folds and classes.\n",
    "- To better select a best model, using Per Class Metrics to determine what parameters to use could enhance which the parameters selected especially for an imbalanced dataset. F1-Score is used to balance out precision and recall and so finding the mean F1-score for each Model and using it in combination with the accuracy of the model to find the best parameters could enhance the performance of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d593d5af-582d-47ca-a341-c83bf318bfeb",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Sometimes, combining different weak classification models can improve the overall performance of the model. **Implement bagging** for each of your three classification models (`model_1`, `model_2`, `model_3`) [from the previous task](#Different-models-and-parameter-search). Store your models performing bagging over your based models calculated in the previous task in variables called `bagged_1`, `bagged_2` and `bagged_3`. Provide your implementation, running any additional evaluation needed, in the **SOLUTION CELL**\n",
    "\n",
    "The **TESTING CELL** will evaluate your 3 bagged models using your own evaluation procedure. It will also make a voting ensemble consisting of your three base models (`model_1`, `model_2`, `model_3`) and another one made of your bagged models (`bagged_1`, `bagged_2` and `bagged_3`), and evaluate these three voting ensembles.\n",
    "\n",
    "**Discuss** the effect on bagging on your base models. Discuss how you chose the bagging parameters, and justify your choice. Discuss the effect using the voting ensemble had on your model performance. Compare the effect of a voting ensemble on the ensemble models to the effect on the base models. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b14274-bfc0-45fc-87e5-96eb7d120a7e",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b8899c-d7fe-4518-bf82-d66442466bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######\n",
    "#### Code  adapted from [2] ####\n",
    "bagged_1 = type(\"DummyClassifier\", (object, ), {\"predict\": lambda self, X: 0 })()\n",
    "bagged_2 = type(\"DummyClassifier\", (object, ), {\"predict\": lambda self, X: 0 })()\n",
    "bagged_3 = type(\"DummyClassifier\", (object, ), {\"predict\": lambda self, X: 0 })()\n",
    "################################\n",
    "# bagged_1 = ...\n",
    "# bagged_2 = ...\n",
    "# bagged_3 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e6e22-4eb4-4c71-9c56-2043507671d4",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d08fc7e-899b-4511-8075-d816f652c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Evaluating model...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf  = VotingClassifier(estimators=[('CLF1', model_1), ('CLF2', model_2), ('CLF3', model_3)], voting='hard')\n",
    "ebclf  = VotingClassifier(estimators=[('BCLF1', bagged_1), ('BCLF2', bagged_2), ('BCLF3', bagged_3)], voting='hard')\n",
    "\n",
    "evaluate_model(bagged_1, X, y)\n",
    "print()\n",
    "evaluate_model(bagged_2, X, y)\n",
    "print()\n",
    "evaluate_model(bagged_3, X, y)\n",
    "print()\n",
    "evaluate_model(eclf, X, y)\n",
    "print()\n",
    "evaluate_model(ebclf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17597da9-0556-4dec-992e-c14e0b9b618a",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e3a0e-f242-404d-a980-e8e9cc928b70",
   "metadata": {},
   "source": [
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4b762-a3ca-46ca-b7fa-6f5d5a58902b",
   "metadata": {},
   "source": [
    "## Final model evaluation\n",
    "\n",
    "Based on all the experiments performed for this assessment, **choose a single best model, evaluate it** with [your evaluation procedure](#Improved-evaluation-strategy) and also **display the confusion matrix**. **Discuss the performance achieved by this model**.\n",
    "\n",
    "**You should attempt this cell even if you have not successfully trained all the models required in this assessment, and comment on the best model which _you_ have obtanied.**\n",
    "\n",
    "Implement your solution in the **SOLUTION CELL** below. Add your discussion to the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ead24-194d-4953-adea-a0fe59caa586",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6739096d-09a1-4d58-82ef-7c2822727451",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d736e-8e98-4bf4-8abe-537fbd297998",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3562ce-0610-4055-8be5-b4c23103f245",
   "metadata": {},
   "source": [
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d346a-6c57-496b-8e0d-d2bf6d51485b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Koklu, M. and Ozkan, I.A., 2020. Multiclass classification of dry beans using computer vision and machine learning techniques. _Computers and Electronics in Agriculture_, 174, p.105507.\n",
    "\n",
    "[2] Murat Koklu: Dry Bean Dataset https://www.muratkoklu.com/datasets/ (accessed 14/08/2024)\n",
    "\n",
    "[3] Mateen Ulhaq, Mike Hordecki (code) https://stackoverflow.com/a/522578/884412 (accessed 24/08/2023)\n",
    "\n",
    "[4] Pazoki, A.R., Farokhi, F. and Pazoki, Z., 2014. Classification of rice grain varieties using two artificial neural networks (MLP and neuro-fuzzy).\n",
    "\n",
    "[5] https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html\n",
    "\n",
    "[6] Classification_report (no date) scikit. Available at: https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html (Accessed: 15 January 2025).\n",
    "\n",
    "[7] Ibm (2024) What is support vector machine?, IBM. Available at: https://www.ibm.com/think/topics/support-vector-machine (Accessed: 15 January 2025). \n",
    "\n",
    "[8]Keylabs (2024) Understanding the F1 score and AUC-Roc Curve, Keylabs. Available at: https://keylabs.ai/blog/understanding-the-f1-score-and-auc-roc-curve/ (Accessed: 15 January 2025). \n",
    "\n",
    "[9]Logisticregression (no date) scikit. Available at: https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html (Accessed: 15 January 2025). \n",
    "\n",
    "[10] Pandas.dataframe.bfill# (no date) pandas.DataFrame.bfill - pandas 2.2.3 documentation. Available at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html (Accessed: 15 January 2025). \n",
    "\n",
    "[11] Pandas.dataframe.head# (no date) pandas.DataFrame.head - pandas 2.2.3 documentation. Available at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html (Accessed: 15 January 2025). \n",
    "\n",
    "[12] Relova, Z. (2021) 3 tips for working with imbalanced datasets, Medium. Available at: https://towardsdatascience.com/3-tips-for-working-with-imbalanced-datasets-a765a0f3a0d0 (Accessed: 15 January 2025). \n",
    "\n",
    "[13] Shafi, A. (2023) K-Nearest Neighbors (KNN) classification with scikit-learn, DataCamp. Available at: https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn (Accessed: 15 January 2025). \n",
    "\n",
    "[14] Shah, R. (2024) Tune hyperparameters with GRIDSEARCHCV, Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/ (Accessed: 15 January 2025). \n",
    "\n",
    "[15] Stratifiedkfold (no date) scikit. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html (Accessed: 15 January 2025). \n",
    "\n",
    "[16] Train test split: What it means and how to use it (no date) Built In. Available at: https://builtin.com/data-science/train-test-split (Accessed: 15 January 2025). \n",
    "\n",
    "[17] What is the accuracy_score function in Sklearn? (no date) Educative. Available at: https://www.educative.io/answers/what-is-the-accuracyscore-function-in-sklearn (Accessed: 15 January 2025). \n",
    "\n",
    "[18] scikit-learn (2024). 1.10. Decision Trees. [online] scikit-learn. Available at: https://scikit-learn.org/1.5/modules/tree.html.\n",
    "\n",
    "‌[19] Ravindran, R. (2023). Overfitting and Pruning in Decision Trees — Improving Model’s Accuracy. [online] Nerd For Tech. Available at: https://medium.com/nerd-for-tech/overfitting-and-pruning-in-decision-trees-improving-models-accuracy-fdbe9ecd1160.\n",
    "\n",
    "‌\n",
    "‌[20] Banerjee, A. (2020). Computational Complexity of SVM. [online] Medium. Available at: https://alekhyo.medium.com/computational-complexity-of-svm-4d3cacf2f952.\n",
    "\n",
    "‌\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
